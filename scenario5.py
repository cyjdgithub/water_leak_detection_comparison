# === pressure_timeframe_rule_learning.py ===
# === flow_timeframe_rule_learning.py ===

# generate_rules_scenario6.py
# === Patch DataLoader (macOS fix) ===
from torch.utils.data import DataLoader as TorchDataLoader
class PatchedDataLoader(TorchDataLoader):
    def __init__(self, *args, **kwargs):
        kwargs['num_workers'] = 0
        super().__init__(*args, **kwargs)
import torch.utils.data
torch.utils.data.DataLoader = PatchedDataLoader

import pandas as pd
from sqlalchemy import create_engine
from aerial import discretization, model, rule_extraction, rule_quality

# === DB setup ===
DB_USER = "postgres"
DB_PASS = "password"
DB_NAME = "leakdb"
DB_HOST = "localhost"
DB_PORT = "5432"
TABLE_NAME = "leakage_wide"

print("ğŸ“¥ Connecting to TimescaleDB...")
engine = create_engine(f"postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}")
df = pd.read_sql_table(TABLE_NAME, engine)

# === Select pressure features only ===
print("ğŸ¯ Selecting pressure_Node_xx columns...")
# === Select pressure features only ===
pressure_cols = [col for col in df.columns if col.startswith("pressure_Node_")]

print(f"Selected pressure columns: {pressure_cols}")

# === Build training table ===
X = df[pressure_cols]
y = df["leak_label"]

# === Discretization ===
print("ğŸ§® Discretizing features...")
discretized_X = discretization.equal_width_discretization(X, n_bins=6)
discretized_df = pd.concat([discretized_X, y.rename("leak_label")], axis=1)

discretized_df.to_csv("discretization/scenario7_discretized.csv", index=False)
print("âœ… Discretized data saved to 'scenario7_discretized.csv'.")

# === Train autoencoder & extract rules ===
print("ğŸ¤– Training autoencoder and extracting rules...")
trained_ae = model.train(discretized_df, epochs=5, lr=1e-3, num_workers=1)

"""rules = rule_extraction.generate_rules(
    trained_ae,
    target_classes=[{"leak_label": "1.0"}, {"leak_label": "0.0"}],
    ant_similarity=0.4,
    cons_similarity=0.8
)"""
# å­¦ leak=1 çš„è§„åˆ™
rules_pos = rule_extraction.generate_rules(
    trained_ae,
    target_classes=[{"leak_label": "1.0"}],
    ant_similarity=0.7,
    cons_similarity=0.9
)

# å­¦ leak=0 çš„è§„åˆ™
rules_neg = rule_extraction.generate_rules(
    trained_ae,
    target_classes=[{"leak_label": "0.0"}],
    ant_similarity=0.5,
    cons_similarity=0.7
)

# åˆå¹¶ rules
rules = rules_pos + rules_neg


if rules:
    stats, rules = rule_quality.calculate_rule_stats(rules, trained_ae.input_vectors)
    pd.DataFrame(rules).to_csv("rules_learned/scenario7_learned_rules.csv", index=False)
    pd.DataFrame([stats]).to_csv("rules_stats/scenario7_rule_stats.csv", index=False)
    print(f"âœ… {len(rules)} rules extracted and saved.")
else:
    print("âš ï¸ No rules found.")


# === Step 7: Rule-based classification report ===
print("\nğŸ” Applying rules to classify samples...")

import pandas as pd
from rule_based_classifier import RuleBasedClassifier
from sklearn.metrics import classification_report

# åŠ è½½è§„åˆ™
rules_df = pd.read_csv("rules_learned/scenario7_learned_rules.csv")   # æ”¹æˆ 7/8 å¯¹åº”æ–‡ä»¶å

# å‡†å¤‡è¾“å…¥æ•°æ®
X = discretized_X  # å·²ç¦»æ•£åŒ–çš„è¾“å…¥ç‰¹å¾ï¼ˆDataFrameï¼‰
y = df["leak_label"]  # åŸå§‹æ ‡ç­¾

# è§„åˆ™åˆ†ç±»å™¨é¢„æµ‹
clf = RuleBasedClassifier()
clf.fit(rules_df)

y_pred = clf.predict(X)

# è¯„ä¼°
report = classification_report(y, y_pred, digits=3)
print(report)

# ä¿å­˜åˆ†ç±»æŠ¥å‘Š
with open("classfication_reports/scenario7_classification_report.txt", "w") as f:
    f.write(report)

print("âœ… Classification report saved.")